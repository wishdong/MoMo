"""
æ‰¹é‡å®éªŒè¿è¡Œè„šæœ¬

åŠŸèƒ½ï¼š
1. è¯»å–experiments_config.jsoné…ç½®æ–‡ä»¶
2. è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒå‘½ä»¤
3. æ”¯æŒæ–­ç‚¹ç»­è®­ï¼ˆæ£€æŸ¥å·²å®Œæˆçš„å®éªŒï¼‰
4. æ”¯æŒå¹¶è¡Œæ‰§è¡Œï¼ˆå¤šGPUï¼‰
5. ç”Ÿæˆå®éªŒæ—¥å¿—
"""

import json
import os
import subprocess
import argparse
from pathlib import Path
from datetime import datetime
import time


def check_experiment_completed(dataset, subject, experiment_id, results_dir='./results'):
    """
    æ£€æŸ¥å®éªŒæ˜¯å¦å·²å®Œæˆ
    
    Args:
        dataset: æ•°æ®é›†åç§°
        subject: å—è¯•è€…ç¼–å·
        experiment_id: å®éªŒID
        results_dir: ç»“æœç›®å½•
    
    Returns:
        bool: Trueè¡¨ç¤ºå·²å®Œæˆï¼ŒFalseè¡¨ç¤ºæœªå®Œæˆ
    """
    result_path = Path(results_dir) / dataset / f'subject{subject}' / experiment_id / 'metrics.json'
    pred_path = Path(results_dir) / dataset / f'subject{subject}' / experiment_id / 'predictions.pkl'
    
    # ä¸¤ä¸ªæ–‡ä»¶éƒ½å­˜åœ¨æ‰ç®—å®Œæˆ
    return result_path.exists() and pred_path.exists()


def get_all_subjects(dataset):
    """
    è·å–æ•°æ®é›†çš„æ‰€æœ‰å—è¯•è€…ç¼–å·ï¼ˆæ ¹æ®å®é™…å¯ç”¨æ•°æ®ï¼‰
    
    Args:
        dataset: æ•°æ®é›†åç§°
    
    Returns:
        list: å—è¯•è€…ç¼–å·åˆ—è¡¨
    """
    dataset_subjects = {
        'DB2': list(range(1, 41)),      # S1-S40 (40ä¸ª)
        'DB3': [2, 4, 5, 6, 9, 11],    # 6ä¸ª
        'DB5': list(range(1, 11)),      # S1-S10 (10ä¸ª)
        'DB7': list(range(2, 13))       # S2-S12 (11ä¸ª)
    }
    return dataset_subjects.get(dataset, [])


def generate_command(dataset, subject, experiment_args, gpu=0, base_args=''):
    """
    ç”Ÿæˆè®­ç»ƒå‘½ä»¤
    
    Args:
        dataset: æ•°æ®é›†åç§°
        subject: å—è¯•è€…ç¼–å·
        experiment_args: å®éªŒç‰¹å®šçš„å‚æ•°
        gpu: GPUç¼–å·
        base_args: åŸºç¡€å‚æ•°ï¼ˆå¦‚batch_size, num_epochsç­‰ï¼‰
    
    Returns:
        str: å®Œæ•´çš„è®­ç»ƒå‘½ä»¤
    """
    cmd = f"python train.py --dataset {dataset} --s {subject} --gpu {gpu} {base_args} {experiment_args}"
    return cmd


def run_experiment_group(config_section, config, args):
    """
    è¿è¡Œä¸€ç»„å®éªŒ
    
    Args:
        config_section: é…ç½®èŠ‚åç§°
        config: é…ç½®å­—å…¸
        args: å‘½ä»¤è¡Œå‚æ•°
    """
    print("=" * 80)
    print(f"ğŸ“Š å®éªŒç»„: {config_section}")
    print(f"ğŸ“ æè¿°: {config.get('description', 'N/A')}")
    print("=" * 80)
    
    datasets = config.get('datasets', [])
    experiments = config.get('experiments', [])
    
    if not datasets or not experiments:
        print(f"âš ï¸  è·³è¿‡ {config_section}: æ²¡æœ‰é…ç½®æ•°æ®é›†æˆ–å®éªŒ")
        return
    
    # æ”¶é›†æ‰€æœ‰å®éªŒä»»åŠ¡
    tasks = []
    
    for dataset in datasets:
        # è·å–å—è¯•è€…åˆ—è¡¨
        if args.subjects == 'all':
            subjects = get_all_subjects(dataset)
        elif args.subjects == 'representative':
            # ä½¿ç”¨ä»£è¡¨æ€§å—è¯•è€…
            rep_key = f"{dataset}_subjects"
            subjects = config.get(rep_key, get_all_subjects(dataset)[:3])
        else:
            # è§£ææŒ‡å®šçš„å—è¯•è€…
            subjects = []
            for part in args.subjects.split(','):
                if '-' in part:
                    start, end = map(int, part.split('-'))
                    subjects.extend(range(start, end + 1))
                else:
                    subjects.append(int(part))
        
        for subject in subjects:
            for exp in experiments:
                exp_id = exp['id']
                exp_args = exp['args']
                
                # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
                if check_experiment_completed(dataset, subject, exp_id, args.results_dir):
                    if args.verbose:
                        print(f"âœ“ å·²å®Œæˆ: {dataset} - S{subject} - {exp_id}")
                    continue
                
                # ç”Ÿæˆå‘½ä»¤
                cmd = generate_command(
                    dataset=dataset,
                    subject=subject,
                    experiment_args=exp_args,
                    gpu=args.gpu,
                    base_args=args.base_args
                )
                
                tasks.append({
                    'dataset': dataset,
                    'subject': subject,
                    'experiment_id': exp_id,
                    'command': cmd,
                    'description': exp.get('description', '')
                })
    
    # æ˜¾ç¤ºä»»åŠ¡ç»Ÿè®¡
    print(f"\nğŸ“ˆ å¾…æ‰§è¡Œä»»åŠ¡: {len(tasks)} ä¸ª")
    
    if len(tasks) == 0:
        print("âœ… æ‰€æœ‰å®éªŒå·²å®Œæˆï¼")
        return
    
    # è¯¢é—®æ˜¯å¦ç»§ç»­
    if not args.yes:
        response = input(f"\næ˜¯å¦å¼€å§‹æ‰§è¡Œè¿™ {len(tasks)} ä¸ªä»»åŠ¡ï¼Ÿ (y/n): ")
        if response.lower() != 'y':
            print("âŒ ç”¨æˆ·å–æ¶ˆ")
            return
    
    # æ‰§è¡Œä»»åŠ¡
    success_count = 0
    fail_count = 0
    
    for i, task in enumerate(tasks, 1):
        print(f"\n{'='*80}")
        print(f"[{i}/{len(tasks)}] {task['dataset']} - S{task['subject']} - {task['experiment_id']}")
        print(f"ğŸ“ {task['description']}")
        print(f"ğŸ–¥ï¸  å‘½ä»¤: {task['command']}")
        print('='*80)
        
        if args.dry_run:
            print("ğŸ’¡ (--dry-runæ¨¡å¼ï¼Œä¸å®é™…æ‰§è¡Œ)")
            continue
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # æ‰§è¡Œå‘½ä»¤
        try:
            result = subprocess.run(task['command'], shell=True, check=True)
            elapsed_time = time.time() - start_time
            
            print(f"\nâœ… å®Œæˆï¼è€—æ—¶: {elapsed_time/60:.1f} åˆ†é’Ÿ")
            success_count += 1
            
            # è®°å½•åˆ°æ—¥å¿—
            log_success(task, elapsed_time, args.log_file)
            
        except subprocess.CalledProcessError as e:
            elapsed_time = time.time() - start_time
            print(f"\nâŒ å¤±è´¥ï¼é”™è¯¯ç : {e.returncode}")
            fail_count += 1
            
            # è®°å½•åˆ°æ—¥å¿—
            log_failure(task, e, elapsed_time, args.log_file)
            
            # å¦‚æœè®¾ç½®äº†--stop-on-errorï¼Œåˆ™åœæ­¢
            if args.stop_on_error:
                print("âš ï¸  æ£€æµ‹åˆ°é”™è¯¯ï¼Œåœæ­¢æ‰§è¡Œï¼ˆ--stop-on-errorï¼‰")
                break
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š æ‰§è¡Œæ€»ç»“")
    print("=" * 80)
    print(f"âœ… æˆåŠŸ: {success_count}")
    print(f"âŒ å¤±è´¥: {fail_count}")
    print(f"â­ï¸  è·³è¿‡: {len(tasks) - success_count - fail_count}")
    print("=" * 80)


def run_hyperparameter_grid_search(args):
    """
    è¿è¡Œè¶…å‚æ•°ç½‘æ ¼æœç´¢ï¼ˆalphaå’Œbetaï¼‰
    """
    print("=" * 80)
    print("ğŸ”¬ è¶…å‚æ•°ç½‘æ ¼æœç´¢ï¼šalpha å’Œ beta")
    print("=" * 80)
    
    # è¯»å–é…ç½®
    with open('experiments_config.json', 'r', encoding='utf-8') as f:
        full_config = json.load(f)
    
    config = full_config.get('hyperparameter_search_alpha_beta', {})
    datasets = config.get('datasets', [])
    alpha_values = config.get('alpha_values', [])
    beta_values = config.get('beta_values', [])
    
    # æ”¶é›†ä»»åŠ¡
    tasks = []
    
    for dataset in datasets:
        # è·å–å—è¯•è€…
        if args.subjects == 'all':
            subjects = get_all_subjects(dataset)
        else:
            subjects = [int(s) for s in args.subjects.split(',')]
        
        for subject in subjects:
            for alpha in alpha_values:
                for beta in beta_values:
                    exp_id = f"HP_a{alpha}_b{beta}"
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
                    if check_experiment_completed(dataset, subject, exp_id, args.results_dir):
                        if args.verbose:
                            print(f"âœ“ å·²å®Œæˆ: {dataset} - S{subject} - {exp_id}")
                        continue
                    
                    # ç”Ÿæˆå‘½ä»¤
                    exp_args = f"--use-disentangle --alpha {alpha} --beta {beta} --save-predictions --experiment_id {exp_id}"
                    cmd = generate_command(dataset, subject, exp_args, args.gpu, args.base_args)
                    
                    tasks.append({
                        'dataset': dataset,
                        'subject': subject,
                        'experiment_id': exp_id,
                        'command': cmd,
                        'description': f'Alpha={alpha}, Beta={beta}'
                    })
    
    print(f"\nğŸ“ˆ å¾…æ‰§è¡Œä»»åŠ¡: {len(tasks)} ä¸ªï¼ˆ{len(alpha_values)}Ã—{len(beta_values)} ç½‘æ ¼ï¼‰")
    
    # åç»­æ‰§è¡Œé€»è¾‘åŒrun_experiment_group
    # ...(çœç•¥ï¼Œé€»è¾‘ç›¸åŒ)


def log_success(task, elapsed_time, log_file):
    """è®°å½•æˆåŠŸçš„å®éªŒ"""
    with open(log_file, 'a', encoding='utf-8') as f:
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        f.write(f"[{timestamp}] âœ… SUCCESS | {task['dataset']} | S{task['subject']} | {task['experiment_id']} | {elapsed_time/60:.1f}min\n")


def log_failure(task, error, elapsed_time, log_file):
    """è®°å½•å¤±è´¥çš„å®éªŒ"""
    with open(log_file, 'a', encoding='utf-8') as f:
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        f.write(f"[{timestamp}] âŒ FAILED  | {task['dataset']} | S{task['subject']} | {task['experiment_id']} | Error: {error}\n")


def main():
    parser = argparse.ArgumentParser(description='æ‰¹é‡å®éªŒè¿è¡Œè„šæœ¬')
    
    # å®éªŒç»„é€‰æ‹©
    parser.add_argument('--group', type=str, default='all',
                        choices=['all', 'main_ablation', 'disentangle_ablation', 
                                'adaptive_fusion_ablation', 'full_model_all_datasets',
                                'hyperparameter_search'],
                        help='è¦è¿è¡Œçš„å®éªŒç»„')
    
    # å—è¯•è€…é€‰æ‹©
    parser.add_argument('--subjects', type=str, default='all',
                        help='å—è¯•è€…é€‰æ‹©ï¼šall, representative, æˆ–æŒ‡å®šå¦‚"1,2,3"æˆ–"1-10"')
    
    # GPUè®¾ç½®
    parser.add_argument('--gpu', type=int, default=0,
                        help='GPUç¼–å·')
    
    # åŸºç¡€å‚æ•°
    parser.add_argument('--base-args', type=str, 
                        default='--batch_size 64 --num_epochs 20',
                        help='æ‰€æœ‰å®éªŒå…±ç”¨çš„åŸºç¡€å‚æ•°')
    
    # æ‰§è¡Œæ§åˆ¶
    parser.add_argument('--dry-run', action='store_true',
                        help='åªæ˜¾ç¤ºå‘½ä»¤ï¼Œä¸å®é™…æ‰§è¡Œ')
    parser.add_argument('--yes', '-y', action='store_true',
                        help='ä¸è¯¢é—®ç›´æ¥æ‰§è¡Œ')
    parser.add_argument('--stop-on-error', action='store_true',
                        help='é‡åˆ°é”™è¯¯ç«‹å³åœæ­¢')
    parser.add_argument('--verbose', '-v', action='store_true',
                        help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    
    # è·¯å¾„è®¾ç½®
    parser.add_argument('--results-dir', type=str, default='./results',
                        help='ç»“æœç›®å½•')
    parser.add_argument('--log-file', type=str, default='./experiment_log.txt',
                        help='æ—¥å¿—æ–‡ä»¶')
    
    args = parser.parse_args()
    
    # è¯»å–é…ç½®æ–‡ä»¶
    config_file = 'experiments_config.json'
    if not os.path.exists(config_file):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return
    
    with open(config_file, 'r', encoding='utf-8') as f:
        full_config = json.load(f)
    
    # æ‰§è¡Œå®éªŒç»„
    if args.group == 'all':
        # ä¾æ¬¡æ‰§è¡Œæ‰€æœ‰ç»„
        groups = ['main_ablation', 'disentangle_ablation', 
                 'adaptive_fusion_ablation', 'full_model_all_datasets']
        for group in groups:
            if group in full_config:
                run_experiment_group(group, full_config[group], args)
    elif args.group == 'hyperparameter_search':
        run_hyperparameter_grid_search(args)
    else:
        # æ‰§è¡ŒæŒ‡å®šç»„
        if args.group in full_config:
            run_experiment_group(args.group, full_config[args.group], args)
        else:
            print(f"âŒ æœªæ‰¾åˆ°å®éªŒç»„: {args.group}")


if __name__ == '__main__':
    main()

