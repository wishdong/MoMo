"""
ä¸»è®­ç»ƒè„šæœ¬
ä½¿ç”¨æ–¹æ³•:
    # é»˜è®¤ï¼šä½¿ç”¨ä¸‰åˆ†æ”¯æŸå¤±
    python train.py --s 10 --gpu 0
    
    # æ¶ˆèå®éªŒï¼šåªä½¿ç”¨èåˆåˆ†æ”¯æŸå¤±
    python train.py --s 10 --gpu 0 --no-branch-loss
    
è®­ç»ƒç­–ç•¥: AdamWç»Ÿä¸€ä¼˜åŒ–å™¨ + ç«¯åˆ°ç«¯è”åˆè®­ç»ƒ
"""

import os
import random
import argparse
import numpy as np
import torch

from config import EMG_Configs, IMU_Configs, DisentangleConfigs, AdaptiveFusionConfigs, get_dataset_config
from models import (
    MultimodalGestureNet, 
    MultimodalGestureNetWithDisentangle,
    MultimodalGestureNetWithAdaptiveFusion
)
from data_loader import load_dataloader_for_both
from trainer import train_model, evaluate_aggregated_all_subjects


def set_seed(seed):
    """è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯å¤ç°æ€§"""
    os.environ['PYTHONHASHSEED'] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True


def main(args):
    """ä¸»è®­ç»ƒæµç¨‹"""
    
    # ==================== èšåˆè¯„ä¼°æ¨¡å¼ ====================
    if args.aggregate_results:
        print("=" * 50)
        print("ğŸ”„ èšåˆè¯„ä¼°æ¨¡å¼")
        print("=" * 50)
        
        # è§£æå—è¯•è€…åˆ—è¡¨
        if args.aggregate_subjects == 'all':
            # æ ¹æ®æ•°æ®é›†è‡ªåŠ¨è·å–æ‰€æœ‰å¯ç”¨å—è¯•è€…
            dataset_config = get_dataset_config(args.dataset)
            if 'available_subjects' in dataset_config:
                subjects = dataset_config['available_subjects']
            else:
                # å›é€€åˆ°1åˆ°num_subjects
                subjects = list(range(1, dataset_config['num_subjects'] + 1))
        else:
            # è§£ææŒ‡å®šçš„å—è¯•è€…ï¼Œä¾‹å¦‚ "1,2,3" æˆ– "1-10"
            subjects = []
            for part in args.aggregate_subjects.split(','):
                if '-' in part:
                    start, end = map(int, part.split('-'))
                    subjects.extend(range(start, end + 1))
                else:
                    subjects.append(int(part))
        
        print(f"å°†èšåˆ {len(subjects)} ä¸ªå—è¯•è€…çš„ç»“æœ: {subjects}")
        
        # ç¡®å®šæ¨¡å‹ç±»å‹
        if args.use_adaptive_fusion:
            model_type = "adaptive_fusion_model"
        elif args.use_disentangle:
            model_type = "disentangle_model"
        else:
            model_type = "base_model"
        
        print(f"æ¨¡å‹ç±»å‹: {model_type}")
        
        # æ‰§è¡Œèšåˆè¯„ä¼°
        aggregated_metrics = evaluate_aggregated_all_subjects(
            subjects=subjects,
            model_type=model_type,
            results_base_dir='./results'
        )
        
        if aggregated_metrics is not None:
            print("\nâœ… èšåˆè¯„ä¼°å®Œæˆï¼")
        else:
            print("\nâŒ èšåˆè¯„ä¼°å¤±è´¥ï¼")
        
        return
    
    # ==================== æ­£å¸¸è®­ç»ƒæ¨¡å¼ ====================
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)
    
    # è®¾ç½®è®¾å¤‡
    device = f'cuda:{args.gpu}' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è·å–æ•°æ®é›†é…ç½®
    dataset_config = get_dataset_config(args.dataset)
    print("=" * 50)
    print(f"æ•°æ®é›†: {dataset_config['name']}")
    print(f"  æ‰‹åŠ¿ç±»åˆ«: {dataset_config['num_class']}")
    print(f"  EMGé€šé“: {dataset_config['emg_channels']}")
    print(f"  IMUé€šé“: {dataset_config['imu_channels']}")
    print(f"  å—è¯•è€…æ•°: {dataset_config['num_subjects']}")
    
    # åŠ è½½æ•°æ®
    print("=" * 50)
    print(f"åŠ è½½å—è¯•è€… {args.s} çš„æ•°æ®...")
    
    train_loader, val_loader, class_counts = load_dataloader_for_both(
        data_dir=args.data_dir,
        subject=args.s,
        batch_size=args.batch_size,
        drop_last=True,
        shuffle=True,
        add_test_to_train_ratio=args.ratio
    )
    
    dataloaders = {'train': train_loader, 'val': val_loader}
    print(f"æ•°æ®åŠ è½½å®Œæˆ")
    
    # æ„å»ºæ¨¡å‹
    print("=" * 50)
    print("æ„å»ºæ¨¡å‹...")
    
    # åˆå§‹åŒ–é…ç½®ï¼ˆæ ¹æ®æ•°æ®é›†åˆ›å»ºï¼‰
    emg_configs = EMG_Configs(dataset=args.dataset)
    imu_configs = IMU_Configs(dataset=args.dataset)
    
    disentangle_config = None
    adaptive_fusion_config = None
    
    if args.use_adaptive_fusion:
        # ä½¿ç”¨å®Œæ•´æ¨¡å‹ï¼šè§£çº ç¼  + è‡ªé€‚åº”èåˆ
        adaptive_fusion_config = AdaptiveFusionConfigs()
        
        # å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
        if hasattr(args, 'unified_dim') and args.unified_dim is not None:
            adaptive_fusion_config.unified_dim = args.unified_dim
        if hasattr(args, 'lambda_align') and args.lambda_align is not None:
            adaptive_fusion_config.lambda_align = args.lambda_align
        if hasattr(args, 'lambda_balance') and args.lambda_balance is not None:
            adaptive_fusion_config.lambda_balance = args.lambda_balance
        
        model = MultimodalGestureNetWithAdaptiveFusion(
            imu_configs, emg_configs,
            d_shared=args.d_shared,
            d_private=args.d_private,
            dropout=DisentangleConfigs.dropout,
            adaptive_fusion_config=adaptive_fusion_config
        )
        print(f"âœ“ ä½¿ç”¨å®Œæ•´æ¨¡å‹ï¼ˆè§£çº ç¼  + è‡ªé€‚åº”èåˆï¼‰")
        print(f"  - å…±äº«è¡¨å¾ç»´åº¦: {args.d_shared}")
        print(f"  - ç‹¬ç‰¹è¡¨å¾ç»´åº¦: {args.d_private}")
        print(f"  - ç»Ÿä¸€èåˆç»´åº¦: {adaptive_fusion_config.unified_dim}")
        print(f"  - è·¯ç”±å™¨éšè—å±‚: {adaptive_fusion_config.router_hidden_dim}")
        
        # é…ç½®è§£çº ç¼ å‚æ•°ï¼ˆè‡ªé€‚åº”èåˆæ¨¡å‹ä¹Ÿéœ€è¦è§£çº ç¼ æŸå¤±ï¼‰
        disentangle_config = DisentangleConfigs()
        if hasattr(args, 'alpha') and args.alpha is not None:
            disentangle_config.alpha = args.alpha
        if hasattr(args, 'beta') and args.beta is not None:
            disentangle_config.beta = args.beta
        disentangle_config.d_shared = args.d_shared
        disentangle_config.d_private = args.d_private
        
    elif args.use_disentangle:
        # åªä½¿ç”¨è§£çº ç¼ æ¨¡å‹
        model = MultimodalGestureNetWithDisentangle(
            imu_configs, emg_configs,
            d_shared=args.d_shared,
            d_private=args.d_private,
            dropout=DisentangleConfigs.dropout
        )
        print(f"âœ“ ä½¿ç”¨è§£çº ç¼ æ¨¡å‹")
        print(f"  - å…±äº«è¡¨å¾ç»´åº¦: {args.d_shared}")
        print(f"  - ç‹¬ç‰¹è¡¨å¾ç»´åº¦: {args.d_private}")
        
        # é…ç½®è§£çº ç¼ å‚æ•°
        disentangle_config = DisentangleConfigs()
        if hasattr(args, 'alpha') and args.alpha is not None:
            disentangle_config.alpha = args.alpha
        if hasattr(args, 'beta') and args.beta is not None:
            disentangle_config.beta = args.beta
        disentangle_config.d_shared = args.d_shared
        disentangle_config.d_private = args.d_private
    else:
        # ä½¿ç”¨åŸæœ‰æ¨¡å‹
        model = MultimodalGestureNet(imu_configs, emg_configs)
        print(f"âœ“ ä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼ˆä¸ä½¿ç”¨è§£çº ç¼ ï¼‰")
    
    model = model.to(device)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ¨¡å‹å‚æ•°æ€»æ•°: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°æ•°: {trainable_params:,}")
    
    # å¼€å§‹è®­ç»ƒ
    print("=" * 50)
    print("å¼€å§‹è®­ç»ƒ...")
    print(f"æŸå¤±ç­–ç•¥: {'ä½¿ç”¨ä¸‰åˆ†æ”¯æŸå¤±' if args.use_branch_loss else 'ä»…ä½¿ç”¨èåˆåˆ†æ”¯æŸå¤±ï¼ˆæ¶ˆèå®éªŒï¼‰'}")
    if args.use_adaptive_fusion:
        print(f"è§£çº ç¼ ç­–ç•¥: å¯ç”¨ï¼ˆÎ±={disentangle_config.alpha}, Î²={disentangle_config.beta}ï¼‰")
        print(f"è‡ªé€‚åº”èåˆç­–ç•¥: å¯ç”¨ï¼ˆÎ»_align={adaptive_fusion_config.lambda_align}, Î»_balance={adaptive_fusion_config.lambda_balance}ï¼‰")
    elif args.use_disentangle:
        print(f"è§£çº ç¼ ç­–ç•¥: å¯ç”¨ï¼ˆÎ±={disentangle_config.alpha}, Î²={disentangle_config.beta}ï¼‰")
    
    best_weights = train_model(
        model=model,
        dataloaders=dataloaders,
        num_epochs=args.num_epochs,
        precision=args.precision,
        device=device,
        use_swanlab=args.use_swanlab,
        swanlab_project=args.swanlab_project,
        subject=args.s,
        dataset=args.dataset,
        experiment_id=args.experiment_id,
        add_test_ratio=args.ratio,
        use_branch_loss=args.use_branch_loss,
        use_disentangle=args.use_disentangle or args.use_adaptive_fusion,  # è‡ªé€‚åº”èåˆä¹Ÿéœ€è¦è§£çº ç¼ 
        disentangle_config=disentangle_config,
        use_adaptive_fusion=args.use_adaptive_fusion,
        adaptive_fusion_config=adaptive_fusion_config,
        save_predictions=args.save_predictions  # æ–°å¢ï¼šæ§åˆ¶æ˜¯å¦ä¿å­˜é¢„æµ‹ç»“æœ
    )
    
    # ä¿å­˜æ¨¡å‹
    print("=" * 50)
    print("ä¿å­˜æ¨¡å‹...")
    
    # åˆ›å»ºç›®å½•ç»“æ„: weights/{dataset}/subject{id}/
    # ä½¿ç”¨experiment_idä½œä¸ºæ–‡ä»¶å
    subject_dir = os.path.join(args.save_dir, args.dataset, f'subject{args.s}')
    os.makedirs(subject_dir, exist_ok=True)
    
    # ä¿å­˜è·¯å¾„: weights/{dataset}/subject{id}/{experiment_id}.pt
    save_path = os.path.join(subject_dir, f'{args.experiment_id}.pt')
    torch.save(best_weights, save_path)
    print(f"æ¨¡å‹å·²ä¿å­˜è‡³: {save_path}")
    
    print("=" * 50)
    print("è®­ç»ƒå®Œæˆï¼")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='EMG-IMUå¤šæ¨¡æ€æ‰‹åŠ¿è¯†åˆ«è®­ç»ƒ')
    
    # æ•°æ®é›†å‚æ•°
    parser.add_argument('--dataset', type=str, default='DB2', 
                        choices=['DB2', 'DB3', 'DB5', 'DB7'],
                        help='æ•°æ®é›†åç§°')
    parser.add_argument('--s', type=int, default=10, 
                        help='å—è¯•è€…ç¼–å·')
    parser.add_argument('--data_dir', type=str, 
                        default='/home/xuweishi/KBS25/MoMo/Momo/processed_data',
                        help='æ•°æ®æ ¹ç›®å½•ï¼ˆåŒ…å«DB2/, DB3/, DB5/, DB7/å­ç›®å½•ï¼‰')
    parser.add_argument('--ratio', type=float, default=0.1,
                        help='ä»æµ‹è¯•é›†ä¸­å–å¤šå°‘æ¯”ä¾‹åŠ å…¥è®­ç»ƒé›† (0-1, é»˜è®¤0.4å³40%%)')
    
    # å®éªŒæ ‡è¯†å‚æ•°
    parser.add_argument('--experiment_id', type=str, default=None,
                        help='å®éªŒIDï¼ˆå¦‚M0_base, D1_private_only, HP_a0.3_b0.5ç­‰ï¼‰ï¼Œç”¨äºæ–‡ä»¶å‘½å')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch_size', type=int, default=64, 
                        help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_epochs', type=int, default=20, 
                        help='æœ€å¤§è®­ç»ƒè½®æ•°')
    parser.add_argument('--precision', type=float, default=1e-8, 
                        help='æ—©åœç²¾åº¦')
    parser.add_argument('--seed', type=int, default=0, 
                        help='éšæœºç§å­')
    
    # è®¾å¤‡å‚æ•°
    parser.add_argument('--gpu', type=int, default=6, 
                        help='GPUç¼–å·')
    
    # ä¿å­˜å‚æ•°
    parser.add_argument('--save_dir', type=str, default='./weights', 
                        help='æ¨¡å‹ä¿å­˜ç›®å½•')
    
    # SwanLabç›‘æ§å‚æ•°
    parser.add_argument('--use_swanlab', action='store_true', default=False,
                        help='æ˜¯å¦ä½¿ç”¨SwanLabç›‘æ§ï¼ˆé»˜è®¤å…³é—­ï¼Œæ‰¹é‡å®éªŒæ—¶å»ºè®®å…³é—­ï¼‰')
    parser.add_argument('--swanlab_project', type=str, default='Gesture-Recognition',
                        help='SwanLabé¡¹ç›®åç§°')
    
    # è®­ç»ƒç­–ç•¥å‚æ•°
    parser.add_argument('--use_branch_loss', action='store_true', default=True,
                        help='æ˜¯å¦ä½¿ç”¨å•æ¨¡æ€åˆ†æ”¯æŸå¤±ï¼ˆé»˜è®¤Trueï¼Œä½¿ç”¨--no-branch-lossç¦ç”¨ï¼‰')
    parser.add_argument('--no-branch-loss', dest='use_branch_loss', action='store_false',
                        help='ç¦ç”¨å•æ¨¡æ€åˆ†æ”¯æŸå¤±ï¼ˆæ¶ˆèå®éªŒï¼‰')
    
    # è§£çº ç¼ å‚æ•°
    parser.add_argument('--use-disentangle', action='store_true', default=False,
                        help='æ˜¯å¦ä½¿ç”¨è§£çº ç¼ æŸå¤±ï¼ˆé»˜è®¤Falseï¼‰')
    parser.add_argument('--d-shared', type=int, default=128,
                        help='å…±äº«è¡¨å¾ç»´åº¦ï¼ˆé»˜è®¤128ï¼‰')
    parser.add_argument('--d-private', type=int, default=64,
                        help='ç‹¬ç‰¹è¡¨å¾ç»´åº¦ï¼ˆé»˜è®¤64ï¼‰')
    parser.add_argument('--alpha', type=float, default=None,
                        help='L_privateæƒé‡ï¼ˆé»˜è®¤ä½¿ç”¨configä¸­çš„å€¼ï¼‰')
    parser.add_argument('--beta', type=float, default=None,
                        help='L_sharedæƒé‡ï¼ˆé»˜è®¤ä½¿ç”¨configä¸­çš„å€¼ï¼‰')
    
    # è‡ªé€‚åº”èåˆå‚æ•°ï¼ˆåˆ›æ–°ç‚¹2ï¼‰
    parser.add_argument('--use-adaptive-fusion', action='store_true', default=False,
                        help='æ˜¯å¦ä½¿ç”¨è‡ªé€‚åº”èåˆï¼ˆé»˜è®¤Falseï¼Œå¯ç”¨æ—¶è‡ªåŠ¨åŒ…å«è§£çº ç¼ ï¼‰')
    parser.add_argument('--unified-dim', type=int, default=None,
                        help='ç»Ÿä¸€èåˆç»´åº¦ï¼ˆé»˜è®¤ä½¿ç”¨configä¸­çš„128ï¼‰')
    parser.add_argument('--lambda-align', type=float, default=None,
                        help='æƒé‡-é‡è¦æ€§å¯¹é½æŸå¤±æƒé‡ï¼ˆé»˜è®¤ä½¿ç”¨configä¸­çš„å€¼ï¼‰')
    parser.add_argument('--lambda-balance', type=float, default=None,
                        help='æƒé‡å¹³è¡¡æŸå¤±æƒé‡ï¼ˆé»˜è®¤ä½¿ç”¨configä¸­çš„å€¼ï¼‰')
    
    # èšåˆè¯„ä¼°å‚æ•°
    parser.add_argument('--save-predictions', action='store_true', default=False,
                        help='æ˜¯å¦ä¿å­˜é¢„æµ‹ç»“æœï¼ˆç”¨äºåç»­èšåˆåˆ†æï¼‰')
    parser.add_argument('--aggregate-results', action='store_true', default=False,
                        help='èšåˆè¯„ä¼°æ¨¡å¼ï¼šåŠ è½½å·²è®­ç»ƒæ¨¡å‹çš„é¢„æµ‹ç»“æœï¼Œç”Ÿæˆèšåˆæ··æ·†çŸ©é˜µ')
    parser.add_argument('--aggregate-subjects', type=str, default='all',
                        help='è¦èšåˆçš„å—è¯•è€…ï¼Œä¾‹å¦‚ "all", "1,2,3", "1-10" ï¼ˆé»˜è®¤allè¡¨ç¤º1-40ï¼‰')
    
    args = parser.parse_args()
    
    # è‡ªåŠ¨ç”Ÿæˆexperiment_idï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
    if args.experiment_id is None:
        if args.use_adaptive_fusion:
            args.experiment_id = "M3_full"
        elif args.use_disentangle:
            args.experiment_id = "M1_disentangle"
        else:
            args.experiment_id = "M0_base"
        
        # å¦‚æœæœ‰è‡ªå®šä¹‰alpha/betaï¼Œæ·»åŠ åˆ°IDä¸­
        if args.alpha is not None or args.beta is not None:
            alpha_val = args.alpha if args.alpha is not None else 0.5
            beta_val = args.beta if args.beta is not None else 0.5
            args.experiment_id += f"_a{alpha_val}_b{beta_val}"
    
    # æ›´æ–°data_dirä¸ºå…·ä½“æ•°æ®é›†è·¯å¾„
    args.data_dir = os.path.join(args.data_dir, args.dataset)
    
    main(args)

