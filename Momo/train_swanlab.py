"""
RMSCMå¤šæ¨¡æ€æ‰‹åŠ¿è¯†åˆ«æ¨¡å‹è®­ç»ƒè„šæœ¬ - SwanLabé›†æˆç‰ˆæœ¬
"""

import os
import sys
import time
import argparse
from pathlib import Path
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
import swanlab

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from model.rmscm_model import MultiModalRMSCM, MultiTaskLoss, get_model_info
from dataset import create_dataloaders


class Trainer:
    """è®­ç»ƒå™¨ç±» - é›†æˆSwanLabç›‘æ§"""
    
    def __init__(self, args):
        self.args = args
        self.device = self._setup_device(args)
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        self.checkpoint_dir = Path(args.checkpoint_dir)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        self.log_dir = Path(args.log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # TensorBoard
        if args.use_tensorboard:
            self.writer = SummaryWriter(log_dir=str(self.log_dir))
        else:
            self.writer = None
        
        # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        self._init_dataloaders()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._init_model()
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
        self._init_optimizer()
        
        # SwanLabåˆå§‹åŒ–ï¼ˆåœ¨æ¨¡å‹åˆ›å»ºä¹‹åï¼‰
        if args.use_swanlab:
            self._init_swanlab()
        
        # è®°å½•æœ€ä½³å‡†ç¡®ç‡å’ŒEarly Stopping
        self.best_acc = 0.0
        self.start_epoch = 0
        self.patience_counter = 0  # Early Stoppingè®¡æ•°å™¨
        
        # å¦‚æœæŒ‡å®šäº†æ¢å¤è®­ç»ƒçš„checkpoint
        if args.resume:
            self._load_checkpoint(args.resume)
    
    def _setup_device(self, args):
        """è®¾ç½®è®¡ç®—è®¾å¤‡ï¼ˆæ”¯æŒGPUé€‰æ‹©ï¼‰"""
        if not torch.cuda.is_available():
            print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
            return torch.device('cpu')
        
        # æ˜¾ç¤ºå¯ç”¨GPUä¿¡æ¯
        gpu_count = torch.cuda.device_count()
        print(f"\n{'='*60}")
        print("GPUè®¾å¤‡ä¿¡æ¯")
        print(f"{'='*60}")
        print(f"å¯ç”¨GPUæ•°é‡: {gpu_count}")
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            print(f"GPU {i}: {torch.cuda.get_device_name(i)} ({props.total_memory / 1024**3:.1f} GB)")
        
        # å¤„ç†è®¾å¤‡é€‰æ‹©
        if args.device == 'cpu':
            print("âœ… ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ")
            return torch.device('cpu')
        elif args.device == 'cuda' or args.device.startswith('cuda:'):
            if args.device == 'cuda':
                # ä½¿ç”¨é»˜è®¤GPUï¼ˆGPU 0ï¼‰
                device_id = 0
                device = torch.device('cuda:0')
            else:
                # è§£ææŒ‡å®šçš„GPU ID
                try:
                    device_id = int(args.device.split(':')[1])
                    if device_id >= gpu_count:
                        print(f"âŒ GPU {device_id} ä¸å­˜åœ¨ï¼Œä½¿ç”¨GPU 0")
                        device_id = 0
                    device = torch.device(f'cuda:{device_id}')
                except (ValueError, IndexError):
                    print(f"âŒ æ— æ•ˆçš„è®¾å¤‡æ ¼å¼: {args.device}ï¼Œä½¿ç”¨GPU 0")
                    device_id = 0
                    device = torch.device('cuda:0')
            
            # è®¾ç½®å½“å‰GPU
            torch.cuda.set_device(device_id)
            
            # æ˜¾ç¤ºGPUä½¿ç”¨ä¿¡æ¯
            print(f"âœ… ä½¿ç”¨GPU {device_id}: {torch.cuda.get_device_name(device_id)}")
            
            # æ˜¾ç¤ºGPUå†…å­˜ä¿¡æ¯
            memory_allocated = torch.cuda.memory_allocated(device_id) / 1024**3
            memory_reserved = torch.cuda.memory_reserved(device_id) / 1024**3  
            memory_total = torch.cuda.get_device_properties(device_id).total_memory / 1024**3
            print(f"GPUå†…å­˜: {memory_allocated:.2f} GB / {memory_total:.1f} GB (å·²åˆ†é…)")
            print(f"GPUå†…å­˜: {memory_reserved:.2f} GB / {memory_total:.1f} GB (å·²é¢„ç•™)")
            
            return device
        else:
            print(f"âŒ æœªçŸ¥è®¾å¤‡: {args.device}ï¼Œä½¿ç”¨GPU 0")
            torch.cuda.set_device(0)
            return torch.device('cuda:0')
    
    def _init_swanlab(self):
        """åˆå§‹åŒ–SwanLab"""
        print(f"\n{'='*60}")
        print("åˆå§‹åŒ–SwanLabç›‘æ§")
        print(f"{'='*60}")
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        try:
            model_info = get_model_info(self.model, self.args.emg_channels, 
                                      self.args.imu_channels, self.args.window_size)
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è·å–æ¨¡å‹ä¿¡æ¯: {e}")
            model_info = None
        
        # å®éªŒé…ç½®
        experiment_config = {
            # æ¨¡å‹å‚æ•°
            "model_name": "MultiModalRMSCM",
            "emg_channels": self.args.emg_channels,
            "imu_channels": self.args.imu_channels, 
            "num_classes": self.args.num_classes,
            "feature_dim": self.args.feature_dim,
            "hidden_dim": self.args.hidden_dim,
            "dropout": self.args.dropout,
            
            # è®­ç»ƒå‚æ•°
            "epochs": self.args.epochs,
            "batch_size": self.args.batch_size,
            "learning_rate": self.args.lr,
            "weight_decay": self.args.weight_decay,
            "optimizer": self.args.optimizer,
            "scheduler": self.args.scheduler,
            "device": str(self.device),
            
            # æ•°æ®å‚æ•°
            "subject": self.args.subject,
            "window_size": self.args.window_size,
            
            # æŸå¤±å‡½æ•°å‚æ•°
            "alpha": self.args.alpha,
            "beta": self.args.beta, 
            "gamma": self.args.gamma,
        }
        
        # æ·»åŠ æ¨¡å‹ä¿¡æ¯åˆ°é…ç½®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if model_info:
            experiment_config.update({
                "model_parameters_M": model_info['total_parameters_M'],
                "emg_input_shape": str(model_info['input_shape_emg']),
                "imu_input_shape": str(model_info['input_shape_imu']),
                "emg_output_shape": str(model_info['output_shape_emg']),
                "imu_output_shape": str(model_info['output_shape_imu']),
                "fusion_output_shape": str(model_info['output_shape_fusion']),
                "final_output_shape": str(model_info['output_shape_final'])
            })
        
        # åˆå§‹åŒ–SwanLabå®éªŒ
        swanlab.init(
            project=self.args.swanlab_project,
            experiment_name=self._get_experiment_name(),
            description=f"EMG+IMUå¤šæ¨¡æ€æ‰‹åŠ¿è¯†åˆ« - å—è¯•è€…{self.args.subject}",
            config=experiment_config,
            logdir=self.args.swanlab_logdir if self.args.swanlab_logdir else None
        )
        
        print("SwanLabåˆå§‹åŒ–å®Œæˆ")
    
    def _get_experiment_name(self):
        """ç”Ÿæˆå®éªŒåç§°"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        return f"RMSCM_S{self.args.subject}_{self.args.optimizer}_lr{self.args.lr}_{timestamp}"
    
    def _init_dataloaders(self):
        """åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨"""
        print(f"\n{'='*60}")
        print("åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨")
        print(f"{'='*60}")
        
        # å¼ºåˆ¶ä½¿ç”¨å†…å­˜åŠ è½½ï¼ˆè§£å†³HDF5è¯»å–ç¼“æ…¢é—®é¢˜ï¼‰
        self.train_loader, self.test_loader = create_dataloaders(
            data_dir=self.args.data_dir,
            batch_size=self.args.batch_size,
            num_workers=self.args.num_workers,
            mode='both',
            load_to_memory=True,  # å¼ºåˆ¶åŠ è½½åˆ°å†…å­˜ï¼Œè§£å†³I/Oç“¶é¢ˆ
            subject=self.args.subject
        )
        
        print(f"æ•°æ®åŠ è½½å®Œæˆ")
        print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(self.train_loader)}")
        print(f"æµ‹è¯•æ‰¹æ¬¡æ•°: {len(self.test_loader)}")
    
    def _init_model(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        print(f"\n{'='*60}")
        print("åˆå§‹åŒ–æ¨¡å‹")
        print(f"{'='*60}")
        
        self.model = MultiModalRMSCM(
            emg_channels=self.args.emg_channels,
            imu_channels=self.args.imu_channels,
            num_classes=self.args.num_classes,
            feature_dim=self.args.feature_dim,
            hidden_dim=self.args.hidden_dim,
            dropout=self.args.dropout
        ).to(self.device)
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        model_info = get_model_info(self.model, self.args.emg_channels, 
                                    self.args.imu_channels, self.args.window_size)
        print(f"æ¨¡å‹å‚æ•°é‡: {model_info['total_parameters_M']:.2f}M")
        print(f"è¾“å…¥å½¢çŠ¶ - EMG: {model_info['input_shape_emg']}")
        print(f"è¾“å…¥å½¢çŠ¶ - IMU: {model_info['input_shape_imu']}")
        print(f"è¾“å‡ºå½¢çŠ¶: {model_info['output_shape_final']}")
        
        # æ¨¡å‹ä¿¡æ¯å·²ç»åœ¨SwanLabé…ç½®ä¸­è®°å½•ï¼Œè¿™é‡Œä¸éœ€è¦é¢å¤–è®°å½•
        
        # åˆå§‹åŒ–æŸå¤±å‡½æ•°
        self.criterion = MultiTaskLoss(
            alpha=self.args.alpha,
            beta=self.args.beta, 
            gamma=self.args.gamma
        )
    
    def _init_optimizer(self):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        print(f"\n{'='*60}")
        print("åˆå§‹åŒ–ä¼˜åŒ–å™¨")
        print(f"{'='*60}")
        
        # ä¼˜åŒ–å™¨
        if self.args.optimizer == 'adam':
            self.optimizer = optim.Adam(
                self.model.parameters(),
                lr=self.args.lr,
                weight_decay=self.args.weight_decay
            )
        elif self.args.optimizer == 'sgd':
            self.optimizer = optim.SGD(
                self.model.parameters(),
                lr=self.args.lr,
                momentum=0.9,
                weight_decay=self.args.weight_decay
            )
        
        print(f"ä¼˜åŒ–å™¨: {self.args.optimizer}")
        print(f"å­¦ä¹ ç‡: {self.args.lr}")
        print(f"æƒé‡è¡°å‡: {self.args.weight_decay}")
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = None
        if self.args.scheduler == 'step':
            self.scheduler = optim.lr_scheduler.StepLR(
                self.optimizer, 
                step_size=self.args.step_size,
                gamma=self.args.gamma_lr
            )
        elif self.args.scheduler == 'cosine':
            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer, 
                T_max=self.args.epochs
            )
        
        if self.scheduler:
            print(f"å­¦ä¹ ç‡è°ƒåº¦å™¨: {self.args.scheduler}")
    
    def _save_checkpoint(self, epoch, acc, is_best=False):
        """ä¿å­˜checkpoint"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'best_acc': self.best_acc,
            'args': self.args
        }
        
        if self.scheduler:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()
        
        # ä¿å­˜æœ€æ–°checkpoint
        latest_path = self.checkpoint_dir / 'latest_checkpoint.pth'
        torch.save(checkpoint, latest_path)
        
        # ä¿å­˜æœ€ä½³checkpoint
        if is_best:
            best_path = self.checkpoint_dir / 'best_checkpoint.pth'
            torch.save(checkpoint, best_path)
            print(f"ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path} (å‡†ç¡®ç‡: {acc:.4f})")
        
        # å®šæœŸä¿å­˜checkpoint
        if (epoch + 1) % self.args.save_freq == 0:
            epoch_path = self.checkpoint_dir / f'checkpoint_epoch_{epoch+1}.pth'
            torch.save(checkpoint, epoch_path)
    
    def _load_checkpoint(self, checkpoint_path):
        """åŠ è½½checkpoint"""
        print(f"\nä» {checkpoint_path} æ¢å¤è®­ç»ƒ")
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.start_epoch = checkpoint['epoch'] + 1
        self.best_acc = checkpoint['best_acc']
        
        if self.scheduler and 'scheduler_state_dict' in checkpoint:
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        print(f"ä»epoch {self.start_epoch} ç»§ç»­è®­ç»ƒ, æœ€ä½³å‡†ç¡®ç‡: {self.best_acc:.4f}")
    
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        total_loss = 0.0
        loss_emg_total = 0.0
        loss_imu_total = 0.0
        loss_fusion_total = 0.0
        
        correct_emg = 0
        correct_imu = 0
        correct_fusion = 0
        correct_final = 0
        total_samples = 0
        
        # æ—¶é—´æµ‹é‡å˜é‡
        epoch_start_time = time.time()
        step_start_time = time.time()
        step_times = []  # å­˜å‚¨æ¯ä¸ªstepçš„æ—¶é—´
        
        for batch_idx, (emg, imu, labels) in enumerate(self.train_loader):
            # æ•°æ®ç§»åˆ°è®¾å¤‡
            emg = emg.to(self.device)
            imu = imu.to(self.device)
            labels = labels.to(self.device)
            
            # å‰å‘ä¼ æ’­
            logit_emg, logit_imu, logit_fusion, logit_final = self.model(emg, imu)
            
            # è®¡ç®—æŸå¤±
            loss, loss_dict = self.criterion(logit_emg, logit_imu, logit_fusion, labels)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            
            # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
            if self.args.grad_clip > 0:
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.grad_clip)
            
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss_dict['total']
            loss_emg_total += loss_dict['emg']
            loss_imu_total += loss_dict['imu']
            loss_fusion_total += loss_dict['fusion']
            
            # è®¡ç®—å‡†ç¡®ç‡
            _, pred_emg = torch.max(logit_emg, 1)
            _, pred_imu = torch.max(logit_imu, 1)
            _, pred_fusion = torch.max(logit_fusion, 1)
            _, pred_final = torch.max(logit_final, 1)
            
            correct_emg += (pred_emg == labels).sum().item()
            correct_imu += (pred_imu == labels).sum().item()
            correct_fusion += (pred_fusion == labels).sum().item()
            correct_final += (pred_final == labels).sum().item()
            total_samples += labels.size(0)
            
            # æ‰“å°è¿›åº¦ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«è¯¦ç»†æ—¶é—´ä¿¡æ¯ï¼‰
            if (batch_idx + 1) % self.args.print_freq == 0:
                # è®¡ç®—å½“å‰stepçš„æ—¶é—´
                current_time = time.time()
                step_time = current_time - step_start_time
                step_times.append(step_time)
                
                # è®¡ç®—å¹³å‡æ‰¹æ¬¡æ—¶é—´å’Œstepæ—¶é—´
                avg_batch_time = step_time / self.args.print_freq
                avg_step_time = sum(step_times) / len(step_times)
                
                # é¢„ä¼°å‰©ä½™æ—¶é—´
                remaining_batches = len(self.train_loader) - (batch_idx + 1)
                remaining_time_epoch = remaining_batches * avg_batch_time
                
                # é¢„ä¼°æ€»å‰©ä½™æ—¶é—´ï¼ˆåŒ…æ‹¬å‰©ä½™epochsï¼‰
                remaining_epochs = self.args.epochs - epoch
                if len(step_times) > 1:  # æœ‰è¶³å¤Ÿæ•°æ®è¿›è¡Œé¢„ä¼°
                    estimated_epoch_time = len(self.train_loader) * avg_batch_time
                    total_remaining_time = remaining_time_epoch + (remaining_epochs - 1) * estimated_epoch_time
                else:
                    total_remaining_time = 0
                
                # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
                def format_time(seconds):
                    if seconds < 60:
                        return f"{seconds:.1f}s"
                    elif seconds < 3600:
                        return f"{seconds/60:.1f}m"
                    else:
                        return f"{seconds/3600:.1f}h"
                
                # è®¡ç®—å½“å‰æŒ‡æ ‡
                avg_loss = total_loss / (batch_idx + 1)
                acc_final = 100.0 * correct_final / total_samples
                progress_percent = (batch_idx + 1) / len(self.train_loader) * 100
                
                # æ‰“å°è¯¦ç»†è¿›åº¦ä¿¡æ¯
                print(f"Epoch [{epoch+1}/{self.args.epochs}] "
                      f"Step [{(batch_idx+1)//self.args.print_freq}] "
                      f"Batch [{batch_idx+1}/{len(self.train_loader)}] ({progress_percent:.1f}%)")
                print(f"  Loss: {avg_loss:.4f} | Acc: {acc_final:.2f}%")
                print(f"  â±ï¸  Stepæ—¶é—´: {format_time(step_time)} "
                      f"| å¹³å‡batch: {avg_batch_time*1000:.1f}ms "
                      f"| å¹³å‡step: {format_time(avg_step_time)}")
                print(f"  ğŸ•’ æœ¬è½®å‰©ä½™: {format_time(remaining_time_epoch)} "
                      f"| è®­ç»ƒå‰©ä½™: {format_time(total_remaining_time)}")
                
                # GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
                if torch.cuda.is_available():
                    gpu_memory_used = torch.cuda.memory_allocated(self.device) / 1024**3
                    gpu_memory_total = torch.cuda.get_device_properties(self.device).total_memory / 1024**3
                    gpu_utilization = gpu_memory_used / gpu_memory_total * 100
                    print(f"  ğŸ“Š GPUå†…å­˜: {gpu_memory_used:.1f}GB/{gpu_memory_total:.1f}GB ({gpu_utilization:.1f}%)")
                
                print("-" * 80)
                
                # é‡ç½®stepè®¡æ—¶å™¨
                step_start_time = current_time
        
        # Epochç»Ÿè®¡
        epoch_time = time.time() - epoch_start_time
        avg_loss = total_loss / len(self.train_loader)
        avg_loss_emg = loss_emg_total / len(self.train_loader)
        avg_loss_imu = loss_imu_total / len(self.train_loader)
        avg_loss_fusion = loss_fusion_total / len(self.train_loader)
        
        acc_emg = 100.0 * correct_emg / total_samples
        acc_imu = 100.0 * correct_imu / total_samples
        acc_fusion = 100.0 * correct_fusion / total_samples
        acc_final = 100.0 * correct_final / total_samples
        
        # è®¡ç®—æ—¶é—´ç›¸å…³æŒ‡æ ‡
        avg_batch_time = epoch_time / len(self.train_loader)
        avg_step_time = sum(step_times) / len(step_times) if step_times else epoch_time / (len(self.train_loader) // self.args.print_freq)
        samples_per_second = total_samples / epoch_time
        
        # è®°å½•åˆ°ç›‘æ§ç³»ç»Ÿ
        train_metrics = {
            'train_loss': avg_loss,
            'train_loss_emg': avg_loss_emg,
            'train_loss_imu': avg_loss_imu,
            'train_loss_fusion': avg_loss_fusion,
            'train_acc_emg': acc_emg,
            'train_acc_imu': acc_imu,
            'train_acc_fusion': acc_fusion,
            'train_acc_final': acc_final,
            'learning_rate': self.optimizer.param_groups[0]['lr'],
            'epoch_time': epoch_time,
            'avg_batch_time_ms': avg_batch_time * 1000,  # æ¯«ç§’
            'avg_step_time': avg_step_time,
            'samples_per_second': samples_per_second,
            'gpu_memory_used_gb': torch.cuda.memory_allocated(self.device) / 1024**3 if torch.cuda.is_available() else 0
        }
        
        # TensorBoardè®°å½•
        if self.writer:
            self.writer.add_scalar('Train/Loss', avg_loss, epoch)
            self.writer.add_scalar('Train/Loss_EMG', avg_loss_emg, epoch)
            self.writer.add_scalar('Train/Loss_IMU', avg_loss_imu, epoch)
            self.writer.add_scalar('Train/Loss_Fusion', avg_loss_fusion, epoch)
            self.writer.add_scalar('Train/Acc_EMG', acc_emg, epoch)
            self.writer.add_scalar('Train/Acc_IMU', acc_imu, epoch)
            self.writer.add_scalar('Train/Acc_Fusion', acc_fusion, epoch)
            self.writer.add_scalar('Train/Acc_Final', acc_final, epoch)
            self.writer.add_scalar('Train/LR', self.optimizer.param_groups[0]['lr'], epoch)
            # æ—¶é—´ç›¸å…³æŒ‡æ ‡
            self.writer.add_scalar('Performance/Epoch_Time', epoch_time, epoch)
            self.writer.add_scalar('Performance/Avg_Batch_Time_ms', avg_batch_time * 1000, epoch)
            self.writer.add_scalar('Performance/Samples_Per_Second', samples_per_second, epoch)
            if torch.cuda.is_available():
                self.writer.add_scalar('Performance/GPU_Memory_GB', torch.cuda.memory_allocated(self.device) / 1024**3, epoch)
        
        # SwanLabè®°å½•
        if self.args.use_swanlab:
            swanlab.log(train_metrics, step=epoch)
        
        return {
            'loss': avg_loss,
            'acc_emg': acc_emg,
            'acc_imu': acc_imu,
            'acc_fusion': acc_fusion,
            'acc_final': acc_final,
            'time': epoch_time
        }
    
    def evaluate(self, epoch):
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()
        
        total_loss = 0.0
        loss_emg_total = 0.0
        loss_imu_total = 0.0
        loss_fusion_total = 0.0
        
        correct_emg = 0
        correct_imu = 0
        correct_fusion = 0
        correct_final = 0
        total_samples = 0
        
        with torch.no_grad():
            for emg, imu, labels in self.test_loader:
                # æ•°æ®ç§»åˆ°è®¾å¤‡
                emg = emg.to(self.device)
                imu = imu.to(self.device)
                labels = labels.to(self.device)
                
                # å‰å‘ä¼ æ’­
                logit_emg, logit_imu, logit_fusion, logit_final = self.model(emg, imu)
                
                # è®¡ç®—æŸå¤±
                loss, loss_dict = self.criterion(logit_emg, logit_imu, logit_fusion, labels)
                total_loss += loss_dict['total']
                loss_emg_total += loss_dict['emg']
                loss_imu_total += loss_dict['imu']
                loss_fusion_total += loss_dict['fusion']
                
                # è®¡ç®—å‡†ç¡®ç‡
                _, pred_emg = torch.max(logit_emg, 1)
                _, pred_imu = torch.max(logit_imu, 1)
                _, pred_fusion = torch.max(logit_fusion, 1)
                _, pred_final = torch.max(logit_final, 1)
                
                correct_emg += (pred_emg == labels).sum().item()
                correct_imu += (pred_imu == labels).sum().item()
                correct_fusion += (pred_fusion == labels).sum().item()
                correct_final += (pred_final == labels).sum().item()
                total_samples += labels.size(0)
        
        # ç»Ÿè®¡
        avg_loss = total_loss / len(self.test_loader)
        avg_loss_emg = loss_emg_total / len(self.test_loader)
        avg_loss_imu = loss_imu_total / len(self.test_loader)
        avg_loss_fusion = loss_fusion_total / len(self.test_loader)
        
        acc_emg = 100.0 * correct_emg / total_samples
        acc_imu = 100.0 * correct_imu / total_samples
        acc_fusion = 100.0 * correct_fusion / total_samples
        acc_final = 100.0 * correct_final / total_samples
        
        # è®°å½•åˆ°ç›‘æ§ç³»ç»Ÿ
        test_metrics = {
            'test_loss': avg_loss,
            'test_loss_emg': avg_loss_emg,
            'test_loss_imu': avg_loss_imu,
            'test_loss_fusion': avg_loss_fusion,
            'test_acc_emg': acc_emg,
            'test_acc_imu': acc_imu,
            'test_acc_fusion': acc_fusion,
            'test_acc_final': acc_final
        }
        
        # TensorBoardè®°å½•
        if self.writer:
            self.writer.add_scalar('Test/Loss', avg_loss, epoch)
            self.writer.add_scalar('Test/Loss_EMG', avg_loss_emg, epoch)
            self.writer.add_scalar('Test/Loss_IMU', avg_loss_imu, epoch)
            self.writer.add_scalar('Test/Loss_Fusion', avg_loss_fusion, epoch)
            self.writer.add_scalar('Test/Acc_EMG', acc_emg, epoch)
            self.writer.add_scalar('Test/Acc_IMU', acc_imu, epoch)
            self.writer.add_scalar('Test/Acc_Fusion', acc_fusion, epoch)
            self.writer.add_scalar('Test/Acc_Final', acc_final, epoch)
        
        # SwanLabè®°å½•
        if self.args.use_swanlab:
            swanlab.log(test_metrics, step=epoch)
        
        return {
            'loss': avg_loss,
            'acc_emg': acc_emg,
            'acc_imu': acc_imu,
            'acc_fusion': acc_fusion,
            'acc_final': acc_final
        }
    
    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print(f"\n{'='*60}")
        print("å¼€å§‹è®­ç»ƒ")
        print(f"{'='*60}")
        print(f"è®¾å¤‡: {self.device}")
        print(f"è®­ç»ƒè½®æ•°: {self.args.epochs}")
        print(f"æ‰¹æ¬¡å¤§å°: {self.args.batch_size}")
        if self.args.early_stopping:
            print(f"Early Stopping: å¼€å¯ (patience={self.args.patience})")
        if self.args.grad_clip > 0:
            print(f"æ¢¯åº¦è£å‰ª: {self.args.grad_clip}")
        
        total_start_time = time.time()
        
        for epoch in range(self.start_epoch, self.args.epochs):
            # è®­ç»ƒ
            train_results = self.train_epoch(epoch)
            
            # æ›´æ–°å­¦ä¹ ç‡
            if self.scheduler:
                self.scheduler.step()
            
            # è¯„ä¼°
            if (epoch + 1) % self.args.eval_freq == 0:
                test_results = self.evaluate(epoch)
                
                print(f"\nEpoch [{epoch+1}/{self.args.epochs}]")
                print(f"è®­ç»ƒ - Loss: {train_results['loss']:.4f}, "
                      f"Acc(EMG/IMU/Fusion/Final): "
                      f"{train_results['acc_emg']:.2f}%/"
                      f"{train_results['acc_imu']:.2f}%/"
                      f"{train_results['acc_fusion']:.2f}%/"
                      f"{train_results['acc_final']:.2f}%")
                print(f"æµ‹è¯• - Loss: {test_results['loss']:.4f}, "
                      f"Acc(EMG/IMU/Fusion/Final): "
                      f"{test_results['acc_emg']:.2f}%/"
                      f"{test_results['acc_imu']:.2f}%/"
                      f"{test_results['acc_fusion']:.2f}%/"
                      f"{test_results['acc_final']:.2f}%")
                print(f"æ—¶é—´: {train_results['time']:.2f}s")
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                is_best = test_results['acc_final'] > self.best_acc
                if is_best:
                    self.best_acc = test_results['acc_final']
                    self.patience_counter = 0  # é‡ç½®patienceè®¡æ•°å™¨
                    
                    # è®°å½•æœ€ä½³å‡†ç¡®ç‡åˆ°SwanLab
                    if self.args.use_swanlab:
                        swanlab.log({
                            'best_accuracy': self.best_acc,
                            'best_epoch': epoch + 1
                        }, step=epoch)
                else:
                    self.patience_counter += 1
                
                # ä¿å­˜checkpoint
                self._save_checkpoint(epoch, test_results['acc_final'], is_best)
                
                # Early Stoppingæ£€æŸ¥
                if self.args.early_stopping and self.patience_counter >= self.args.patience:
                    print(f"\nEarly Stoppingè§¦å‘ï¼è¿ç»­{self.args.patience}ä¸ªè¯„ä¼°å‘¨æœŸæœªæå‡")
                    print(f"æœ€ä½³å‡†ç¡®ç‡: {self.best_acc:.4f}")
                    break
        
        # è®­ç»ƒå®Œæˆ
        total_time = time.time() - total_start_time
        print(f"\n{'='*60}")
        print("è®­ç»ƒå®Œæˆ")
        print(f"{'='*60}")
        print(f"æ€»æ—¶é—´: {total_time:.2f}s ({total_time/3600:.2f}h)")
        print(f"æœ€ä½³å‡†ç¡®ç‡: {self.best_acc:.4f}")
        
        # è®°å½•è®­ç»ƒæ€»ç»“åˆ°SwanLab
        if self.args.use_swanlab:
            swanlab.log({
                'final_best_accuracy': self.best_acc,
                'total_training_time_hours': total_time / 3600,
                'training_completed': True
            })
            
            # å®Œæˆå®éªŒ
            swanlab.finish()
        
        # å…³é—­TensorBoard
        if self.writer:
            self.writer.close()


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='RMSCMå¤šæ¨¡æ€æ‰‹åŠ¿è¯†åˆ«è®­ç»ƒ - SwanLabé›†æˆç‰ˆæœ¬')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--data_dir', type=str, default='processed_data',
                       help='é¢„å¤„ç†æ•°æ®ç›®å½•')
    parser.add_argument('--subject', type=int, default=10,
                       help='å—è¯•è€…ç¼–å· (10, 23, 36)')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--emg_channels', type=int, default=12,
                       help='EMGé€šé“æ•°')
    parser.add_argument('--imu_channels', type=int, default=36,
                       help='IMUé€šé“æ•°')
    parser.add_argument('--num_classes', type=int, default=50,
                       help='ç±»åˆ«æ•°')
    parser.add_argument('--window_size', type=int, default=400,
                       help='çª—å£å¤§å°ï¼ˆæ ·æœ¬ç‚¹æ•°ï¼‰')
    parser.add_argument('--feature_dim', type=int, default=64,
                       help='ç‰¹å¾ç»´åº¦')
    parser.add_argument('--hidden_dim', type=int, default=64,
                       help='éšè—å±‚ç»´åº¦')
    parser.add_argument('--dropout', type=float, default=0.5,
                       help='Dropoutæ¯”ç‡')
    
    # æŸå¤±å‡½æ•°å‚æ•°
    parser.add_argument('--alpha', type=float, default=1.0,
                       help='EMGæŸå¤±æƒé‡')
    parser.add_argument('--beta', type=float, default=1.0,
                       help='IMUæŸå¤±æƒé‡')
    parser.add_argument('--gamma', type=float, default=1.0,
                       help='FusionæŸå¤±æƒé‡')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=100,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=32,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--lr', type=float, default=0.001,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-4,
                       help='æƒé‡è¡°å‡')
    parser.add_argument('--optimizer', type=str, default='adam',
                       choices=['adam', 'sgd'], help='ä¼˜åŒ–å™¨')
    parser.add_argument('--scheduler', type=str, default='step',
                       choices=['step', 'cosine', 'none'], help='å­¦ä¹ ç‡è°ƒåº¦å™¨')
    parser.add_argument('--step_size', type=int, default=30,
                       help='StepLRçš„step_size')
    parser.add_argument('--gamma_lr', type=float, default=0.1,
                       help='StepLRçš„gamma')
    
    # æ•°æ®åŠ è½½å‚æ•°
    parser.add_argument('--num_workers', type=int, default=4,
                       help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    parser.add_argument('--load_to_memory', action='store_true',
                       help='æ˜¯å¦å°†æ•°æ®åŠ è½½åˆ°å†…å­˜')
    
    # é˜²æ­¢è¿‡æ‹Ÿåˆå‚æ•°
    parser.add_argument('--early_stopping', action='store_true',
                       help='æ˜¯å¦å¯ç”¨Early Stopping')
    parser.add_argument('--patience', type=int, default=10,
                       help='Early Stoppingçš„patienceï¼ˆè¿ç»­å¤šå°‘ä¸ªè¯„ä¼°å‘¨æœŸä¸æå‡å°±åœæ­¢ï¼‰')
    parser.add_argument('--grad_clip', type=float, default=0.0,
                       help='æ¢¯åº¦è£å‰ªé˜ˆå€¼ï¼ˆ0è¡¨ç¤ºä¸è£å‰ªï¼‰')
    parser.add_argument('--eval_freq', type=int, default=1,
                       help='è¯„ä¼°é¢‘ç‡ï¼ˆæ¯éš”å‡ ä¸ªepochè¯„ä¼°ä¸€æ¬¡ï¼‰')
    
    # ç›‘æ§å‚æ•°
    parser.add_argument('--use_tensorboard', action='store_true', default=False,
                       help='æ˜¯å¦ä½¿ç”¨TensorBoardç›‘æ§')
    parser.add_argument('--use_swanlab', action='store_true', default=True,
                       help='æ˜¯å¦ä½¿ç”¨SwanLabç›‘æ§')
    parser.add_argument('--swanlab_project', type=str, default='Momo-Gesture-Recognition',
                       help='SwanLabé¡¹ç›®åç§°')
    parser.add_argument('--swanlab_logdir', type=str, default=None,
                       help='SwanLabæ—¥å¿—ç›®å½•ï¼ˆå¯é€‰ï¼‰')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--device', type=str, default='cuda:0',
                       help='è®¾å¤‡é€‰æ‹©: cpu, cuda, cuda:0, cuda:1, ..., cuda:7 (é»˜è®¤: cuda:0)')
    parser.add_argument('--checkpoint_dir', type=str, default='checkpoints',
                       help='checkpointä¿å­˜ç›®å½•')
    parser.add_argument('--log_dir', type=str, default='logs',
                       help='æ—¥å¿—ä¿å­˜ç›®å½•')
    parser.add_argument('--print_freq', type=int, default=10,
                       help='æ‰“å°é¢‘ç‡')
    parser.add_argument('--save_freq', type=int, default=10,
                       help='ä¿å­˜checkpointé¢‘ç‡')
    parser.add_argument('--resume', type=str, default='',
                       help='æ¢å¤è®­ç»ƒçš„checkpointè·¯å¾„')
    
    args = parser.parse_args()
    return args


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(args)
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train()


if __name__ == '__main__':
    main()
